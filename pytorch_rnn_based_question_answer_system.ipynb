{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f935c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dbd6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          question      answer\n",
      "0                   What is the capital of France?       Paris\n",
      "1                  What is the capital of Germany?      Berlin\n",
      "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
      "3  What is the largest planet in our solar system?     Jupiter\n",
      "4   What is the boiling point of water in Celsius?         100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('100_Unique_QA_Dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1ed741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\",'')\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    return text.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0775741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab\n",
    "vocab = {'<UNK>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8f2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "    # print(row['question'],row['answer'])\n",
    "    tokenized_question=tokenize(row['question'])\n",
    "    tokenized_answer = tokenize(row['answer'])\n",
    "    \n",
    "    merged_token=tokenized_question + tokenized_answer\n",
    "    for token in merged_token:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d7e48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8d597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert word into numerical indices\n",
    "def text_to_indices(text,vocab):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "        else:\n",
    "            indexed_text.append(vocab['<UNK>'])\n",
    "    return indexed_text\n",
    "\n",
    "\n",
    "# text_to_indices(\"What is capital of France?\",vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2c3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f383f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self,df,vocab):\n",
    "        self.df=df\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __len__(self,):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        numerical_question = text_to_indices(self.df.iloc[index]['question'],self.vocab)\n",
    "        numerical_answer = text_to_indices(self.df.iloc[index]['answer'],self.vocab)\n",
    "        return torch.tensor(numerical_question),torch.tensor(numerical_answer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7abd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df,vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d814c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa68c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n"
     ]
    }
   ],
   "source": [
    "for question,answer in dataloader:\n",
    "    print(question,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c5a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture of RNN\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585fed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n",
    "        self.rnn =nn.RNN(50,64,batch_first=True)\n",
    "        self.fc= nn.Linear(64,vocab_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,question):\n",
    "        embedded_question = self.embedding(question)\n",
    "        hidden,final= self.rnn(embedded_question)\n",
    "        output = self.fc(final.squeeze(0))\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "408459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= nn.Embedding(324,embedding_dim=0)\n",
    "# y = nn.RNN(50,60,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8140eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fb5012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b499d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr =learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09b892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 , Loss: 522.601129\n",
      "Epoch 2 , Loss: 457.242719\n",
      "Epoch 3 , Loss: 379.274297\n",
      "Epoch 4 , Loss: 316.719943\n",
      "Epoch 5 , Loss: 265.864625\n",
      "Epoch 6 , Loss: 218.690829\n",
      "Epoch 7 , Loss: 174.248908\n",
      "Epoch 8 , Loss: 136.680828\n",
      "Epoch 9 , Loss: 105.167872\n",
      "Epoch 10 , Loss: 80.261959\n",
      "Epoch 11 , Loss: 62.111665\n",
      "Epoch 12 , Loss: 48.386006\n",
      "Epoch 13 , Loss: 38.238930\n",
      "Epoch 14 , Loss: 31.275081\n",
      "Epoch 15 , Loss: 25.782332\n",
      "Epoch 16 , Loss: 21.627101\n",
      "Epoch 17 , Loss: 18.458121\n",
      "Epoch 18 , Loss: 15.771088\n",
      "Epoch 19 , Loss: 13.545308\n",
      "Epoch 20 , Loss: 11.798768\n",
      "Epoch 21 , Loss: 10.496070\n",
      "Epoch 22 , Loss: 9.012820\n",
      "Epoch 23 , Loss: 7.922178\n",
      "Epoch 24 , Loss: 7.044049\n",
      "Epoch 25 , Loss: 6.290388\n",
      "Epoch 26 , Loss: 5.653000\n",
      "Epoch 27 , Loss: 5.103973\n",
      "Epoch 28 , Loss: 4.626724\n",
      "Epoch 29 , Loss: 4.207681\n",
      "Epoch 30 , Loss: 3.838425\n",
      "Epoch 31 , Loss: 3.522766\n",
      "Epoch 32 , Loss: 3.248671\n",
      "Epoch 33 , Loss: 2.988909\n",
      "Epoch 34 , Loss: 2.762930\n",
      "Epoch 35 , Loss: 2.558385\n",
      "Epoch 36 , Loss: 2.372990\n",
      "Epoch 37 , Loss: 2.206495\n",
      "Epoch 38 , Loss: 2.055220\n",
      "Epoch 39 , Loss: 1.917823\n",
      "Epoch 40 , Loss: 1.792039\n",
      "Epoch 41 , Loss: 1.677873\n",
      "Epoch 42 , Loss: 1.568752\n",
      "Epoch 43 , Loss: 1.472019\n",
      "Epoch 44 , Loss: 1.382099\n",
      "Epoch 45 , Loss: 1.297092\n",
      "Epoch 46 , Loss: 1.218270\n",
      "Epoch 47 , Loss: 1.148950\n",
      "Epoch 48 , Loss: 1.081383\n",
      "Epoch 49 , Loss: 1.020762\n",
      "Epoch 50 , Loss: 0.962011\n",
      "Epoch 51 , Loss: 0.908180\n",
      "Epoch 52 , Loss: 0.858001\n",
      "Epoch 53 , Loss: 0.810984\n",
      "Epoch 54 , Loss: 0.767335\n",
      "Epoch 55 , Loss: 0.725756\n",
      "Epoch 56 , Loss: 0.688287\n",
      "Epoch 57 , Loss: 0.652062\n",
      "Epoch 58 , Loss: 0.617483\n",
      "Epoch 59 , Loss: 0.584788\n",
      "Epoch 60 , Loss: 0.554910\n",
      "Epoch 61 , Loss: 0.526078\n",
      "Epoch 62 , Loss: 0.500086\n",
      "Epoch 63 , Loss: 0.474595\n",
      "Epoch 64 , Loss: 0.451205\n",
      "Epoch 65 , Loss: 0.428557\n",
      "Epoch 66 , Loss: 0.406754\n",
      "Epoch 67 , Loss: 0.386807\n",
      "Epoch 68 , Loss: 0.368096\n",
      "Epoch 69 , Loss: 0.349724\n",
      "Epoch 70 , Loss: 0.333158\n",
      "Epoch 71 , Loss: 0.316662\n",
      "Epoch 72 , Loss: 0.301632\n",
      "Epoch 73 , Loss: 0.287400\n",
      "Epoch 74 , Loss: 0.273178\n",
      "Epoch 75 , Loss: 0.260578\n",
      "Epoch 76 , Loss: 0.247787\n",
      "Epoch 77 , Loss: 0.236120\n",
      "Epoch 78 , Loss: 0.225309\n",
      "Epoch 79 , Loss: 0.214343\n",
      "Epoch 80 , Loss: 0.204425\n",
      "Epoch 81 , Loss: 0.194829\n",
      "Epoch 82 , Loss: 0.185583\n",
      "Epoch 83 , Loss: 0.177046\n",
      "Epoch 84 , Loss: 0.169075\n",
      "Epoch 85 , Loss: 0.161012\n",
      "Epoch 86 , Loss: 0.153545\n",
      "Epoch 87 , Loss: 0.146540\n",
      "Epoch 88 , Loss: 0.139959\n",
      "Epoch 89 , Loss: 0.133397\n",
      "Epoch 90 , Loss: 0.127272\n",
      "Epoch 91 , Loss: 0.121685\n",
      "Epoch 92 , Loss: 0.115979\n",
      "Epoch 93 , Loss: 0.110786\n",
      "Epoch 94 , Loss: 0.105720\n",
      "Epoch 95 , Loss: 0.100920\n",
      "Epoch 96 , Loss: 0.096300\n",
      "Epoch 97 , Loss: 0.092024\n",
      "Epoch 98 , Loss: 0.087829\n",
      "Epoch 99 , Loss: 0.083849\n",
      "Epoch 100 , Loss: 0.080078\n"
     ]
    }
   ],
   "source": [
    "# training Loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for question,answer in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model(question)\n",
    "\n",
    "        # loss calculate\n",
    "        loss = criterion(output,answer[0])\n",
    "\n",
    "        # gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss = total_loss+loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} , Loss: {total_loss:4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "280b12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Predicition\n",
    "# def predict(model,question,threshold=0.8):\n",
    "\n",
    "#     # convert question to number\n",
    "#     numerical_question = text_to_indices(question,vocab)\n",
    "\n",
    "#     # convert to tensor\n",
    "#     question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "\n",
    "#     # send to model\n",
    "#     output = model(question_tensor)\n",
    "\n",
    "#     # converts logits to probability\n",
    "#     probs = torch.nn.functional.softmax(output,dim=1)\n",
    "\n",
    "#     # find max probability\n",
    "#     value,index = torch.max(probs,dim=1)\n",
    "\n",
    "#     if value < threshold:\n",
    "#         print(\"I don't know\")\n",
    "    \n",
    "#     return list(vocab.keys())[index]\n",
    "\n",
    "def predict(model, question, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Predict the answer for a given question using the model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: trained PyTorch model\n",
    "        question: str, the input question\n",
    "        threshold: float, minimum probability required to return an answer\n",
    "    \n",
    "    Returns:\n",
    "        predicted answer as a string or \"I don't know\" if confidence is below threshold\n",
    "    \"\"\"\n",
    "    # convert question to numerical indices\n",
    "    numerical_question = text_to_indices(question, vocab)\n",
    "\n",
    "    # convert to tensor\n",
    "    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "\n",
    "    # send to model\n",
    "    output = model(question_tensor)\n",
    "\n",
    "    # convert logits to probabilities\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    # find max probability and index\n",
    "    value, index = torch.max(probs, dim=1)\n",
    "\n",
    "    # check threshold\n",
    "    if value.item() < threshold:\n",
    "        return \"I don't know\"\n",
    "    \n",
    "    # return predicted word/label\n",
    "    return list(vocab.keys())[index.item()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6b22c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question\")\n",
    "answer = predict(model,question).capitalize()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a19bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
